# Clasificación

En este capítulo, se te presentarán los problemas de clasifiación y aprenderás a resolverlos mediante técnicas de aprendizaje supervisado. Aprenderás a dividir los datos en conjuntos de entrenamiento y de prueba, ajustar un modelo, hacer predicciones y evaluar la precisión. Descubrirás la relación entre la complejidad del modelo y el rendimiento, aplicando lo que aprendas a un conjunto de datos de rotación, donde clasificarás el estado de rotación de los clientes de una empresa de telecomunicaciones.

## Machine learning con scikit-learn

-   ¿Qué es el machine learning?

    -   Es el proceso mediante el cual:
        -   Se da a los ordenadores la capacidad de aprender a tomar decisiones a partir de datos.
        -   ¡Sin haber sido programados explícitamente!

-   Ejemplos de machine learning

    -   Clasificación de correos de spam o no en relación al contenido y su remitente.
    -   Agrupar libros por categorías en función de las palabras que contiene.

-   Aprendizaje no supervisado

    -   Descubrir patrones ocultos a partir de datos no etiquetados.
    -   Ejemplo
        -   Agrupar a los clientes en categorías distintas (agrupación en clústeres)

            ![](images/paste-1.png){width="83%"}

-   Aprendizaje supervisado

    -   Los valores previstos son conocidos.

    -   Objetivo: predecir los valores objetivo de los datos no vistos, dadas las características.

        ![](images/paste-2.png){width="80%"}

-   Tipos de aprendizaje supervisado

    +--------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+
    | -   Clasificación: La variable objetivo consta de categorías.            | -   Regresión: La variable objetivo es continua.                                                                                                           |
    |                                                                          |                                                                                                                                                            |
    |     Ejemplo: Predecir si una transferencia bancaria es fraudulenta o no. |     Ejemplo: Un modelo puede utilizar características como el número de habitaciones y el tamaño de una propiedad para predecir el precio de la propiedad. |
    +--------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+

-   Convenciones de denominación

    -   Característica = variable predictora = variable independiente

    -   Variable objetivo = variable dependiente = variable de respuesta

-   Antes de utilizar el aprendizaje supervisado

    -   Requisitos:
        -   Que no falten valores.
        -   Que los datos esten en formato numérico.
        -   Que los datos esten almacenados en un DataFrame de pandas o en una matriz de Numpy.
    -   Hay que realizar primero un análisis exploratorio de datos (AED)

-   Sintaxis de scikit-learn

    -   Scikit-learn sigue la misma sintaxis para todos los modelos de aprendizaje supervisado lo que hace que el flujo de trabajo sea reproducible.

```{python}
#| echo: true
#| eval: false
from sklearn.module import Model
model = Model()
model.fit(X, y)
predictions = model.predict(X_new)
print(predictions)
```

![](images/paste-3.png)

### Clasificación binaria

Hay dos tipos de aprendizaje supervisado: clasificación y regresión. La clasificación binaria se utiliza para predecir una variable objetivo que solo tiene dos etiquetas, normalmente representados numéricamente con un cero o un uno.

A continuación se muestra la página `.head()` de un conjunto de datos `churn_df`. Puedes esperar que el resto de los datos contengan valores similares.

![](images/paste-4.png)

Observando estos datos, ¿Qué columna podría ser la variable objetivo de la clasificación binaria?

**Respuestas posibles**

-   [ ] "`customer_service_calls`"

-   [ ] "`total_night_charge`"

-   [x] "`churn`"

-   [ ] "`account_lenght`"

`churn` tiene valores de `0` y `1`, por lo que se puede predecir utilizando un modelo de clasificación binaria.

### El flujo de trabajo del aprendizaje supervisado

Recuerda que sckikit-learn ofrece un flujo de trabajo repetible para utilizar modelos de aprendizaje supervisado con el fin de predecir los valores de la variable objetivo cuando se presentan nuevos datos.

Reordena el pseudocódigo proporcionado para que represente con precisión el flujo de trabajo de construir un modelo de aprendizaje supervisado y hacer predicciones.

#### Instrucciones

-   Arrastra los bloques de código en el orden correcto para representar cómo se ejecutaría el flujo de trabajo de aprendizaje supervisado.

    ![](images/paste-5.png){width="80%"}

Puedes ver cómo scikit-learn permite hacer predicciones ¡con solo unas pocas líneas de código!

## El reto de la clasificación

-   Clasificar etiquetas de datos no vistos

1.  Se construye un modelo.

2.  El modelo aprende de los datos etiquetados que le pasamos.

3.  Le pasamos datos no etiquetados al modelo como entrada.

4.  El modelo predice las etiquetas de los datos no vistos.

    -   Datos etiquetados = datos de entrenamiento

-   K vecinos más cercanos (KNN)
    -   Predecir la etiqueta de un punto de datos:
        -   Observando los `k` puntos de datos etiquetados más cercanos.
        -   Utilizando el voto por mayoría.

|                           |                           |
|---------------------------|---------------------------|
| si k = 3                  | si k = 5                  |
| ![](images/paste-7.png)   | ![](images/paste-9.png)   |
| Se clasificaría como roja | Se clasificaría como azul |

-   Intuición KNN

    Se muestra un gráfico de dispersión que muestra la tarifa nocturna total frente a la tarifa diaria total de los clientes de una empresa de telecomunicaciones. Azul representa a los clientes que se han dado de baja y los de rojo a los que no.

    |                          |                          |
    |--------------------------|--------------------------|
    | ![](images/paste-10.png) | ![](images/paste-11.png) |

    KNN crea un límite de decisión para predecir si los clientes se darán de baja. Se prevee que los clientes en la franja con fondo gris, se darán de baja.

-   Utilizar scikit-learn para ajustar un clasificador

    ```{python}
    #| echo: true
    #| eval: false
    from sklearn.neighbors import KNeighborsClassifier
    X = churn_df[["total_day_charge", "total_eve_charge"]].values
    y = churn_df["churn"].values
    print(X.shape, y.shape)
    ```

    ![](images/paste-13.png)

    ```{python}
    #| echo: true
    #| eval: false
    knn = KNeighborsClassifier(n_neighbors=15)
    knn.fit(X, y)
    ```

-   Predecir con datos no etiquetados

```{python}
#| echo: true
#| eval: false
X_new = np.array([[56.8, 17.5],
                  [24.4, 24.1],
                  [50.1, 10.9]])

print(X_new.shape)
```

![](images/paste-14.png)

```{python}
#| echo: true
#| eval: false
predictions = knn.predict(X_new)
print('Predictions: {}' .format(predictions))
```

![](images/paste-15.png)

### Ajustar KNN: k vecinos más cercanos

En este ejercicio, construirás tu primer modelo de clasificación utilizando el conjunto de datos `churn_df`, que se ha precargado para el resto del capítulo.

El objetivo, `churn` tiene que ser una sola columna con el mismo múmero de observaciones que los datos de las características. Los datos de las características ya se han convertido en matrices `numpy`.

"`account_length`" y "`costumer_service_calls`" se tratan como características porque la duración de la cuenta indica fidelidad del cliente, las llamadas frecuentes al servicio de atención al cliente pueden ser señal de insatisfacción y ambas pueden ser buenos predictores de la rotación.

#### Instrucciones

-   Importa `KNeighborsClassifier` desde `sklearn.neighbors`.
-   Instncia un `KNeighborsClassifier` llamado `knn` con `6` vecinos.
-   Ajusta el clasificador a los datos utilizando el método `.fit()`.

```{python}
import pandas as pd

ruta = './data/churn_df.csv'
churn_df = pd.read_csv(ruta)
churn_df.head()
```

```{python}
# Import KNeigborsClassifier
from sklearn.neighbors import KNeighborsClassifier

y = churn_df['churn'].values
X = churn_df[['account_length', 'customer_service_calls']].values

# Create a KNN classifier with 6 neighbors
knn = KNeighborsClassifier(n_neighbors=6)

# Fit the classifier to the data
knn.fit(X, y)
```

¡Excelente! Ahora que tu clasificador KNN ha sido ajustado a los datos, puede ser utilizado para predecir las etiquetas de nuevos puntos de datos.

### Predecir KNN: k vecinos más cercanos

Ahora que has ajustado tu clasificador KNN, puedes utilizarlo para predecir la etiqueta de nuevos puntos de datos. Para el entrenamiento se utilizaron todos los datos disponibles, pero, afortunadamente, hay nuevas observaciones disponibles. Se han precargado como `X_new`.

```{python}
import numpy as np
X_new = np.array([[30.0, 17.5],
                  [107.0, 24.1],
                  [213.0, 10.9]])
```

#### Instrucciones

-   Crea `y_pred` prediciendo los valores objetivo de las características no vistas `X_new` utilizando el modelo `knn`.

-   Imprime las etiquetas predichas para el conjunto de predicciones.

```{python}
# Predict the labs for the X_new
y_pred = knn.predict(X_new)

# Print the predictions
print("Predictions: {}".format(y_pred))
```

El modelo ha predicho que los primeros y terceros clientes no se darán de baja en el nuevo array. Pero, ¿cómo sabemos qué tan precisas son estas predicciones? Vamos a explorar cómo medir el rendimiento de un modelo en el próximo video.

## Medir el rendimiento del modelo

-   Medir el rendimiento del modelo

    -   En clasificación, se utiliza a menudo la métrica de la precisión.

    -   Precisión: $$
        \frac{\text{Predicciones correctas}}{\text{total de observaciones}}
        $$

    -   ¿Cómo medimos la precisión?

    -   Podría calcular la precisión de los datos utilizados para ajustar el clasificador.

    -   NO sería indicativo de la capacidad de generalización

-   Precisión del cálculo

    ![](images/paste-16.png){width="60%"}

-   Entrenamiento/prueba de la división

    ```{python}
    #| echo: true
    #| eval: false
    from sklearn.model_selection import train_test_split
    X_train, X_text, y_train, y_test = train_test_split(X, y, text_size=0.3, random_state=21, stratify=y)

    knn = KNeighborsClassifier(n_neighbors=6)
    knn.fit(X_train, y_train)
    print(knn.score(X_text, y_test))
    ```

    ![](images/paste-17.png)

-   Complejidad del modelo

    -   k mayor = modelo menos complejo = puede provocar un ajuste insuficiente (underfitting)

    -   k menor = modelo más complejo = puede llevar a un sobreajuste (overfitting)

        ![](images/paste-18.png){width="80%"}

-   Complejidad del modelo y sobreajuste o o ajuste insuficiente

    ```{python}
    #| echo: true
    #| eval: false
    train_accuracies = {}
    test_accuracies = {}
    neighbors = np.arange(1, 26)
    for neighbor in neighbors:
        knn = KNeighborsClassifier(n_neighbors=neighbor)
        knn.fit(X_train, y_train)
        train_accuracies[neighbor] = knn.score(X_train, y_train)
        test_accuracies[neighbor] = knn.score(X_test, y_test)
    ```

-   Representación gráfica de nuestros resultados

    ```{python}
    #| echo: true
    #| eval: false
    plt.figure(figsize=(8, 6))
    plt.title("KNN: Varying Number of Neighbors")
    plt.plot(neighbors, train_accuracies.values(), label="Training Accuracy")
    plt.plot(neighbors, test_accuracies.values(), label="Testing Accuracy")
    plt.legend()
    plt.xlabel("Number of Neighbors")
    plt.ylabel("Accuracy")
    plt.show()
    ```

-   Curva de complejidad del modelo

    ![](images/paste-19.png){width="80%"}

### División entrenamiento/prueba + cálculo de precisión

### Sobreajuste e infraajuste

### Visualizar la complejidad del modelo