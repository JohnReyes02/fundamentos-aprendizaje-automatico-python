{
  "hash": "7236c62f65763d6c7c1fab3151610daa",
  "result": {
    "engine": "jupyter",
    "markdown": "# Clasificación\n\nEn este capítulo, se te presentarán los problemas de clasifiación y aprenderás a resolverlos mediante técnicas de aprendizaje supervisado. Aprenderás a dividir los datos en conjuntos de entrenamiento y de prueba, ajustar un modelo, hacer predicciones y evaluar la precisión. Descubrirás la relación entre la complejidad del modelo y el rendimiento, aplicando lo que aprendas a un conjunto de datos de rotación, donde clasificarás el estado de rotación de los clientes de una empresa de telecomunicaciones.\n\n## Machine learning con scikit-learn\n\n-   ¿Qué es el machine learning?\n\n    -   Es el proceso mediante el cual:\n        -   Se da a los ordenadores la capacidad de aprender a tomar decisiones a partir de datos.\n        -   ¡Sin haber sido programados explícitamente!\n\n-   Ejemplos de machine learning\n\n    -   Clasificación de correos de spam o no en relación al contenido y su remitente.\n    -   Agrupar libros por categorías en función de las palabras que contiene.\n\n-   Aprendizaje no supervisado\n\n    -   Descubrir patrones ocultos a partir de datos no etiquetados.\n    -   Ejemplo\n        -   Agrupar a los clientes en categorías distintas (agrupación en clústeres)\n\n            ![](images/paste-1.png){width=\"83%\"}\n\n-   Aprendizaje supervisado\n\n    -   Los valores previstos son conocidos.\n\n    -   Objetivo: predecir los valores objetivo de los datos no vistos, dadas las características.\n\n        ![](images/paste-2.png){width=\"80%\"}\n\n-   Tipos de aprendizaje supervisado\n\n    +--------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+\n    | -   Clasificación: La variable objetivo consta de categorías.            | -   Regresión: La variable objetivo es continua.                                                                                                           |\n    |                                                                          |                                                                                                                                                            |\n    |     Ejemplo: Predecir si una transferencia bancaria es fraudulenta o no. |     Ejemplo: Un modelo puede utilizar características como el número de habitaciones y el tamaño de una propiedad para predecir el precio de la propiedad. |\n    +--------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n-   Convenciones de denominación\n\n    -   Característica = variable predictora = variable independiente\n\n    -   Variable objetivo = variable dependiente = variable de respuesta\n\n-   Antes de utilizar el aprendizaje supervisado\n\n    -   Requisitos:\n        -   Que no falten valores.\n        -   Que los datos esten en formato numérico.\n        -   Que los datos esten almacenados en un DataFrame de pandas o en una matriz de Numpy.\n    -   Hay que realizar primero un análisis exploratorio de datos (AED)\n\n-   Sintaxis de scikit-learn\n\n    -   Scikit-learn sigue la misma sintaxis para todos los modelos de aprendizaje supervisado lo que hace que el flujo de trabajo sea reproducible.\n\n::: {#4d7cbe1d .cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.module import Model\nmodel = Model()\nmodel.fit(X, y)\npredictions = model.predict(X_new)\nprint(predictions)\n```\n:::\n\n\n![](images/paste-3.png)\n\n### Clasificación binaria\n\nHay dos tipos de aprendizaje supervisado: clasificación y regresión. La clasificación binaria se utiliza para predecir una variable objetivo que solo tiene dos etiquetas, normalmente representados numéricamente con un cero o un uno.\n\nA continuación se muestra la página `.head()` de un conjunto de datos `churn_df`. Puedes esperar que el resto de los datos contengan valores similares.\n\n![](images/paste-4.png)\n\nObservando estos datos, ¿Qué columna podría ser la variable objetivo de la clasificación binaria?\n\n**Respuestas posibles**\n\n-   [ ] \"`customer_service_calls`\"\n\n-   [ ] \"`total_night_charge`\"\n\n-   [x] \"`churn`\"\n\n-   [ ] \"`account_lenght`\"\n\n`churn` tiene valores de `0` y `1`, por lo que se puede predecir utilizando un modelo de clasificación binaria.\n\n### El flujo de trabajo del aprendizaje supervisado\n\nRecuerda que sckikit-learn ofrece un flujo de trabajo repetible para utilizar modelos de aprendizaje supervisado con el fin de predecir los valores de la variable objetivo cuando se presentan nuevos datos.\n\nReordena el pseudocódigo proporcionado para que represente con precisión el flujo de trabajo de construir un modelo de aprendizaje supervisado y hacer predicciones.\n\n#### Instrucciones\n\n-   Arrastra los bloques de código en el orden correcto para representar cómo se ejecutaría el flujo de trabajo de aprendizaje supervisado.\n\n    ![](images/paste-5.png){width=\"80%\"}\n\nPuedes ver cómo scikit-learn permite hacer predicciones ¡con solo unas pocas líneas de código!\n\n## El reto de la clasificación\n\n-   Clasificar etiquetas de datos no vistos\n\n1.  Se construye un modelo.\n\n2.  El modelo aprende de los datos etiquetados que le pasamos.\n\n3.  Le pasamos datos no etiquetados al modelo como entrada.\n\n4.  El modelo predice las etiquetas de los datos no vistos.\n\n    -   Datos etiquetados = datos de entrenamiento\n\n-   K vecinos más cercanos (KNN)\n    -   Predecir la etiqueta de un punto de datos:\n        -   Observando los `k` puntos de datos etiquetados más cercanos.\n        -   Utilizando el voto por mayoría.\n\n|                           |                           |\n|---------------------------|---------------------------|\n| si k = 3                  | si k = 5                  |\n| ![](images/paste-7.png)   | ![](images/paste-9.png)   |\n| Se clasificaría como roja | Se clasificaría como azul |\n\n-   Intuición KNN\n\n    Se muestra un gráfico de dispersión que muestra la tarifa nocturna total frente a la tarifa diaria total de los clientes de una empresa de telecomunicaciones. Azul representa a los clientes que se han dado de baja y los de rojo a los que no.\n\n    |                          |                          |\n    |--------------------------|--------------------------|\n    | ![](images/paste-10.png) | ![](images/paste-11.png) |\n\n    KNN crea un límite de decisión para predecir si los clientes se darán de baja. Se prevee que los clientes en la franja con fondo gris, se darán de baja.\n\n-   Utilizar scikit-learn para ajustar un clasificador\n\n\n    ::: {#c644bf34 .cell execution_count=2}\n    ``` {.python .cell-code}\n    from sklearn.neighbors import KNeighborsClassifier\n    X = churn_df[[\"total_day_charge\", \"total_eve_charge\"]].values\n    y = churn_df[\"churn\"].values\n    print(X.shape, y.shape)\n    ```\n    :::\n    \n    \n    ![](images/paste-13.png)\n\n\n    ::: {#1cc0ef2c .cell execution_count=3}\n    ``` {.python .cell-code}\n    knn = KNeighborsClassifier(n_neighbors=15)\n    knn.fit(X, y)\n    ```\n    :::\n    \n    \n-   Predecir con datos no etiquetados\n\n::: {#0a2a2366 .cell execution_count=4}\n``` {.python .cell-code}\nX_new = np.array([[56.8, 17.5],\n                  [24.4, 24.1],\n                  [50.1, 10.9]])\n\nprint(X_new.shape)\n```\n:::\n\n\n![](images/paste-14.png)\n\n::: {#bf8f393b .cell execution_count=5}\n``` {.python .cell-code}\npredictions = knn.predict(X_new)\nprint('Predictions: {}' .format(predictions))\n```\n:::\n\n\n![](images/paste-15.png)\n\n### Ajustar KNN: k vecinos más cercanos\n\nEn este ejercicio, construirás tu primer modelo de clasificación utilizando el conjunto de datos `churn_df`, que se ha precargado para el resto del capítulo.\n\nEl objetivo, `churn` tiene que ser una sola columna con el mismo múmero de observaciones que los datos de las características. Los datos de las características ya se han convertido en matrices `numpy`.\n\n\"`account_length`\" y \"`costumer_service_calls`\" se tratan como características porque la duración de la cuenta indica fidelidad del cliente, las llamadas frecuentes al servicio de atención al cliente pueden ser señal de insatisfacción y ambas pueden ser buenos predictores de la rotación.\n\n#### Instrucciones\n\n-   Importa `KNeighborsClassifier` desde `sklearn.neighbors`.\n-   Instncia un `KNeighborsClassifier` llamado `knn` con `6` vecinos.\n-   Ajusta el clasificador a los datos utilizando el método `.fit()`.\n\n::: {#08d961a2 .cell execution_count=6}\n``` {.python .cell-code}\nimport pandas as pd\n\nruta = './data/churn_df.csv'\nchurn_df = pd.read_csv(ruta)\nchurn_df.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>account_length</th>\n      <th>total_day_charge</th>\n      <th>total_eve_charge</th>\n      <th>total_night_charge</th>\n      <th>total_intl_charge</th>\n      <th>customer_service_calls</th>\n      <th>churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>101</td>\n      <td>45.85</td>\n      <td>17.65</td>\n      <td>9.64</td>\n      <td>1.22</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>73</td>\n      <td>22.30</td>\n      <td>9.05</td>\n      <td>9.98</td>\n      <td>2.75</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>86</td>\n      <td>24.62</td>\n      <td>17.53</td>\n      <td>11.49</td>\n      <td>3.13</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>59</td>\n      <td>34.73</td>\n      <td>21.02</td>\n      <td>9.66</td>\n      <td>3.24</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>129</td>\n      <td>27.42</td>\n      <td>18.75</td>\n      <td>10.11</td>\n      <td>2.59</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#2b53b8bf .cell execution_count=7}\n``` {.python .cell-code}\n# Import KNeigborsClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\ny = churn_df['churn'].values\nX = churn_df[['account_length', 'customer_service_calls']].values\n\n# Create a KNN classifier with 6 neighbors\nknn = KNeighborsClassifier(n_neighbors=6)\n\n# Fit the classifier to the data\nknn.fit(X, y)\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n``````{=html}\n<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n}\n\n#sk-container-id-1.light {\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: black;\n  --sklearn-color-background: white;\n  --sklearn-color-border-box: black;\n  --sklearn-color-icon: #696969;\n}\n\n#sk-container-id-1.dark {\n  --sklearn-color-text-on-default-background: white;\n  --sklearn-color-background: #111;\n  --sklearn-color-border-box: white;\n  --sklearn-color-icon: #878787;\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: center;\n  justify-content: center;\n  gap: 0.5em;\n}\n\n#sk-container-id-1 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  display: none;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  display: block;\n  width: 100%;\n  overflow: visible;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-unfitted-level-0);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n  color: var(--sklearn-color-fitted-level-3);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-0);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n  color: var(--sklearn-color-fitted-level-0);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-unfitted-level-0);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n\n.estimator-table {\n    font-family: monospace;\n}\n\n.estimator-table summary {\n    padding: .5rem;\n    cursor: pointer;\n}\n\n.estimator-table summary::marker {\n    font-size: 0.7rem;\n}\n\n.estimator-table details[open] {\n    padding-left: 0.1rem;\n    padding-right: 0.1rem;\n    padding-bottom: 0.3rem;\n}\n\n.estimator-table .parameters-table {\n    margin-left: auto !important;\n    margin-right: auto !important;\n    margin-top: 0;\n}\n\n.estimator-table .parameters-table tr:nth-child(odd) {\n    background-color: #fff;\n}\n\n.estimator-table .parameters-table tr:nth-child(even) {\n    background-color: #f6f6f6;\n}\n\n.estimator-table .parameters-table tr:hover {\n    background-color: #e0e0e0;\n}\n\n.estimator-table table td {\n    border: 1px solid rgba(106, 105, 104, 0.232);\n}\n\n/*\n    `table td`is set in notebook with right text-align.\n    We need to overwrite it.\n*/\n.estimator-table table td.param {\n    text-align: left;\n    position: relative;\n    padding: 0;\n}\n\n.user-set td {\n    color:rgb(255, 94, 0);\n    text-align: left !important;\n}\n\n.user-set td.value {\n    color:rgb(255, 94, 0);\n    background-color: transparent;\n}\n\n.default td {\n    color: black;\n    text-align: left !important;\n}\n\n.user-set td i,\n.default td i {\n    color: black;\n}\n\n/*\n    Styles for parameter documentation links\n    We need styling for visited so jupyter doesn't overwrite it\n*/\na.param-doc-link,\na.param-doc-link:link,\na.param-doc-link:visited {\n    text-decoration: underline dashed;\n    text-underline-offset: .3em;\n    color: inherit;\n    display: block;\n    padding: .5em;\n}\n\n/* \"hack\" to make the entire area of the cell containing the link clickable */\na.param-doc-link::before {\n    position: absolute;\n    content: \"\";\n    inset: 0;\n}\n\n.param-doc-description {\n    display: none;\n    position: absolute;\n    z-index: 9999;\n    left: 0;\n    padding: .5ex;\n    margin-left: 1.5em;\n    color: var(--sklearn-color-text);\n    box-shadow: .3em .3em .4em #999;\n    width: max-content;\n    text-align: left;\n    max-height: 10em;\n    overflow-y: auto;\n\n    /* unfitted */\n    background: var(--sklearn-color-unfitted-level-0);\n    border: thin solid var(--sklearn-color-unfitted-level-3);\n}\n\n/* Fitted state for parameter tooltips */\n.fitted .param-doc-description {\n    /* fitted */\n    background: var(--sklearn-color-fitted-level-0);\n    border: thin solid var(--sklearn-color-fitted-level-3);\n}\n\n.param-doc-link:hover .param-doc-description {\n    display: block;\n}\n\n.copy-paste-icon {\n    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n    background-repeat: no-repeat;\n    background-size: 14px 14px;\n    background-position: 0;\n    display: inline-block;\n    width: 14px;\n    height: 14px;\n    cursor: pointer;\n}\n</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n        <div class=\"estimator-table\">\n            <details>\n                <summary>Parameters</summary>\n                <table class=\"parameters-table\">\n                  <tbody>\n                    \n        <tr class=\"user-set\">\n            <td><i class=\"copy-paste-icon\"\n                 onclick=\"copyToClipboard('n_neighbors',\n                          this.parentElement.nextElementSibling)\"\n            ></i></td>\n            <td class=\"param\">\n        <a class=\"param-doc-link\"\n            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#:~:text=n_neighbors,-int%2C%20default%3D5\">\n            n_neighbors\n            <span class=\"param-doc-description\">n_neighbors: int, default=5<br><br>Number of neighbors to use by default for :meth:`kneighbors` queries.</span>\n        </a>\n    </td>\n            <td class=\"value\">6</td>\n        </tr>\n    \n\n        <tr class=\"default\">\n            <td><i class=\"copy-paste-icon\"\n                 onclick=\"copyToClipboard('weights',\n                          this.parentElement.nextElementSibling)\"\n            ></i></td>\n            <td class=\"param\">\n        <a class=\"param-doc-link\"\n            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#:~:text=weights,-%7B%27uniform%27%2C%20%27distance%27%7D%2C%20callable%20or%20None%2C%20default%3D%27uniform%27\">\n            weights\n            <span class=\"param-doc-description\">weights: {'uniform', 'distance'}, callable or None, default='uniform'<br><br>Weight function used in prediction.  Possible values:<br><br>- 'uniform' : uniform weights.  All points in each neighborhood<br>  are weighted equally.<br>- 'distance' : weight points by the inverse of their distance.<br>  in this case, closer neighbors of a query point will have a<br>  greater influence than neighbors which are further away.<br>- [callable] : a user-defined function which accepts an<br>  array of distances, and returns an array of the same shape<br>  containing the weights.<br><br>Refer to the example entitled<br>:ref:`sphx_glr_auto_examples_neighbors_plot_classification.py`<br>showing the impact of the `weights` parameter on the decision<br>boundary.</span>\n        </a>\n    </td>\n            <td class=\"value\">&#x27;uniform&#x27;</td>\n        </tr>\n    \n\n        <tr class=\"default\">\n            <td><i class=\"copy-paste-icon\"\n                 onclick=\"copyToClipboard('algorithm',\n                          this.parentElement.nextElementSibling)\"\n            ></i></td>\n            <td class=\"param\">\n        <a class=\"param-doc-link\"\n            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#:~:text=algorithm,-%7B%27auto%27%2C%20%27ball_tree%27%2C%20%27kd_tree%27%2C%20%27brute%27%7D%2C%20default%3D%27auto%27\">\n            algorithm\n            <span class=\"param-doc-description\">algorithm: {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'<br><br>Algorithm used to compute the nearest neighbors:<br><br>- 'ball_tree' will use :class:`BallTree`<br>- 'kd_tree' will use :class:`KDTree`<br>- 'brute' will use a brute-force search.<br>- 'auto' will attempt to decide the most appropriate algorithm<br>  based on the values passed to :meth:`fit` method.<br><br>Note: fitting on sparse input will override the setting of<br>this parameter, using brute force.</span>\n        </a>\n    </td>\n            <td class=\"value\">&#x27;auto&#x27;</td>\n        </tr>\n    \n\n        <tr class=\"default\">\n            <td><i class=\"copy-paste-icon\"\n                 onclick=\"copyToClipboard('leaf_size',\n                          this.parentElement.nextElementSibling)\"\n            ></i></td>\n            <td class=\"param\">\n        <a class=\"param-doc-link\"\n            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#:~:text=leaf_size,-int%2C%20default%3D30\">\n            leaf_size\n            <span class=\"param-doc-description\">leaf_size: int, default=30<br><br>Leaf size passed to BallTree or KDTree.  This can affect the<br>speed of the construction and query, as well as the memory<br>required to store the tree.  The optimal value depends on the<br>nature of the problem.</span>\n        </a>\n    </td>\n            <td class=\"value\">30</td>\n        </tr>\n    \n\n        <tr class=\"default\">\n            <td><i class=\"copy-paste-icon\"\n                 onclick=\"copyToClipboard('p',\n                          this.parentElement.nextElementSibling)\"\n            ></i></td>\n            <td class=\"param\">\n        <a class=\"param-doc-link\"\n            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#:~:text=p,-float%2C%20default%3D2\">\n            p\n            <span class=\"param-doc-description\">p: float, default=2<br><br>Power parameter for the Minkowski metric. When p = 1, this is equivalent<br>to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.<br>For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected<br>to be positive.</span>\n        </a>\n    </td>\n            <td class=\"value\">2</td>\n        </tr>\n    \n\n        <tr class=\"default\">\n            <td><i class=\"copy-paste-icon\"\n                 onclick=\"copyToClipboard('metric',\n                          this.parentElement.nextElementSibling)\"\n            ></i></td>\n            <td class=\"param\">\n        <a class=\"param-doc-link\"\n            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#:~:text=metric,-str%20or%20callable%2C%20default%3D%27minkowski%27\">\n            metric\n            <span class=\"param-doc-description\">metric: str or callable, default='minkowski'<br><br>Metric to use for distance computation. Default is \"minkowski\", which<br>results in the standard Euclidean distance when p = 2. See the<br>documentation of `scipy.spatial.distance<br><https://docs.scipy.org/doc/scipy/reference/spatial.distance.html>`_ and<br>the metrics listed in<br>:class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric<br>values.<br><br>If metric is \"precomputed\", X is assumed to be a distance matrix and<br>must be square during fit. X may be a :term:`sparse graph`, in which<br>case only \"nonzero\" elements may be considered neighbors.<br><br>If metric is a callable function, it takes two arrays representing 1D<br>vectors as inputs and must return one value indicating the distance<br>between those vectors. This works for Scipy's metrics, but is less<br>efficient than passing the metric name as a string.</span>\n        </a>\n    </td>\n            <td class=\"value\">&#x27;minkowski&#x27;</td>\n        </tr>\n    \n\n        <tr class=\"default\">\n            <td><i class=\"copy-paste-icon\"\n                 onclick=\"copyToClipboard('metric_params',\n                          this.parentElement.nextElementSibling)\"\n            ></i></td>\n            <td class=\"param\">\n        <a class=\"param-doc-link\"\n            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#:~:text=metric_params,-dict%2C%20default%3DNone\">\n            metric_params\n            <span class=\"param-doc-description\">metric_params: dict, default=None<br><br>Additional keyword arguments for the metric function.</span>\n        </a>\n    </td>\n            <td class=\"value\">None</td>\n        </tr>\n    \n\n        <tr class=\"default\">\n            <td><i class=\"copy-paste-icon\"\n                 onclick=\"copyToClipboard('n_jobs',\n                          this.parentElement.nextElementSibling)\"\n            ></i></td>\n            <td class=\"param\">\n        <a class=\"param-doc-link\"\n            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n            n_jobs\n            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of parallel jobs to run for neighbors search.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br>Doesn't affect :meth:`fit` method.</span>\n        </a>\n    </td>\n            <td class=\"value\">None</td>\n        </tr>\n    \n                  </tbody>\n                </table>\n            </details>\n        </div>\n    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n    // Get the parameter prefix from the closest toggleable content\n    const toggleableContent = element.closest('.sk-toggleable__content');\n    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n\n    const originalStyle = element.style;\n    const computedStyle = window.getComputedStyle(element);\n    const originalWidth = computedStyle.width;\n    const originalHTML = element.innerHTML.replace('Copied!', '');\n\n    navigator.clipboard.writeText(fullParamName)\n        .then(() => {\n            element.style.width = originalWidth;\n            element.style.color = 'green';\n            element.innerHTML = \"Copied!\";\n\n            setTimeout(() => {\n                element.innerHTML = originalHTML;\n                element.style = originalStyle;\n            }, 2000);\n        })\n        .catch(err => {\n            console.error('Failed to copy:', err);\n            element.style.color = 'red';\n            element.innerHTML = \"Failed!\";\n            setTimeout(() => {\n                element.innerHTML = originalHTML;\n                element.style = originalStyle;\n            }, 2000);\n        });\n    return false;\n}\n\ndocument.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n    const toggleableContent = element.closest('.sk-toggleable__content');\n    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n    const paramName = element.parentElement.nextElementSibling\n        .textContent.trim().split(' ')[0];\n    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n\n    element.setAttribute('title', fullParamName);\n});\n\n\n/**\n * Adapted from Skrub\n * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n * @returns \"light\" or \"dark\"\n */\nfunction detectTheme(element) {\n    const body = document.querySelector('body');\n\n    // Check VSCode theme\n    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n\n    if (themeKindAttr && themeNameAttr) {\n        const themeKind = themeKindAttr.toLowerCase();\n        const themeName = themeNameAttr.toLowerCase();\n\n        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n            return \"dark\";\n        }\n        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n            return \"light\";\n        }\n    }\n\n    // Check Jupyter theme\n    if (body.getAttribute('data-jp-theme-light') === 'false') {\n        return 'dark';\n    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n        return 'light';\n    }\n\n    // Guess based on a parent element's color\n    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n    if (match) {\n        const [r, g, b] = [\n            parseFloat(match[1]),\n            parseFloat(match[2]),\n            parseFloat(match[3])\n        ];\n\n        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n\n        if (luma > 180) {\n            // If the text is very bright we have a dark theme\n            return 'dark';\n        }\n        if (luma < 75) {\n            // If the text is very dark we have a light theme\n            return 'light';\n        }\n        // Otherwise fall back to the next heuristic.\n    }\n\n    // Fallback to system preference\n    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n}\n\n\nfunction forceTheme(elementId) {\n    const estimatorElement = document.querySelector(`#${elementId}`);\n    if (estimatorElement === null) {\n        console.error(`Element with id ${elementId} not found.`);\n    } else {\n        const theme = detectTheme(estimatorElement);\n        estimatorElement.classList.add(theme);\n    }\n}\n\nforceTheme('sk-container-id-1');</script></body>\n``````\n:::\n:::\n\n\n¡Excelente! Ahora que tu clasificador KNN ha sido ajustado a los datos, puede ser utilizado para predecir las etiquetas de nuevos puntos de datos.\n\n### Predecir KNN: k vecinos más cercanos\n\nAhora que has ajustado tu clasificador KNN, puedes utilizarlo para predecir la etiqueta de nuevos puntos de datos. Para el entrenamiento se utilizaron todos los datos disponibles, pero, afortunadamente, hay nuevas observaciones disponibles. Se han precargado como `X_new`.\n\n::: {#1ada06ba .cell execution_count=8}\n``` {.python .cell-code}\nimport numpy as np\nX_new = np.array([[30.0, 17.5],\n                  [107.0, 24.1],\n                  [213.0, 10.9]])\n```\n:::\n\n\n#### Instrucciones\n\n-   Crea `y_pred` prediciendo los valores objetivo de las características no vistas `X_new` utilizando el modelo `knn`.\n\n-   Imprime las etiquetas predichas para el conjunto de predicciones.\n\n::: {#2327de58 .cell execution_count=9}\n``` {.python .cell-code}\n# Predict the labs for the X_new\ny_pred = knn.predict(X_new)\n\n# Print the predictions\nprint(\"Predictions: {}\".format(y_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPredictions: [0 1 0]\n```\n:::\n:::\n\n\nEl modelo ha predicho que los primeros y terceros clientes no se darán de baja en el nuevo array. Pero, ¿cómo sabemos qué tan precisas son estas predicciones? Vamos a explorar cómo medir el rendimiento de un modelo en el próximo video.\n\n## Medir el rendimiento del modelo\n\n-   Medir el rendimiento del modelo\n\n    -   En clasificación, se utiliza a menudo la métrica de la precisión.\n\n    -   Precisión: $$\n        \\frac{\\text{Predicciones correctas}}{\\text{total de observaciones}}\n        $$\n\n    -   ¿Cómo medimos la precisión?\n\n    -   Podría calcular la precisión de los datos utilizados para ajustar el clasificador.\n\n    -   NO sería indicativo de la capacidad de generalización\n\n-   Precisión del cálculo\n\n    ![](images/paste-16.png){width=\"60%\"}\n\n-   Entrenamiento/prueba de la división\n\n\n    ::: {#70cecde6 .cell execution_count=10}\n    ``` {.python .cell-code}\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n    \n    knn = KNeighborsClassifier(n_neighbors=6)\n    knn.fit(X_train, y_train)\n    print(knn.score(X_text, y_test))\n    ```\n    :::\n    \n    \n    ![](images/paste-17.png)\n\n-   Complejidad del modelo\n\n    -   k mayor = modelo menos complejo = puede provocar un ajuste insuficiente (underfitting)\n\n    -   k menor = modelo más complejo = puede llevar a un sobreajuste (overfitting)\n\n        ![](images/paste-18.png){width=\"80%\"}\n\n-   Complejidad del modelo y sobreajuste o o ajuste insuficiente\n\n\n    ::: {#14743d56 .cell execution_count=11}\n    ``` {.python .cell-code}\n    train_accuracies = {}\n    test_accuracies = {}\n    neighbors = np.arange(1, 26)\n    for neighbor in neighbors:\n        knn = KNeighborsClassifier(n_neighbors=neighbor)\n        knn.fit(X_train, y_train)\n        train_accuracies[neighbor] = knn.score(X_train, y_train)\n        test_accuracies[neighbor] = knn.score(X_test, y_test)\n    ```\n    :::\n    \n    \n-   Representación gráfica de nuestros resultados\n\n\n    ::: {#8efae60a .cell execution_count=12}\n    ``` {.python .cell-code}\n    plt.figure(figsize=(8, 6))\n    plt.title(\"KNN: Varying Number of Neighbors\")\n    plt.plot(neighbors, train_accuracies.values(), label=\"Training Accuracy\")\n    plt.plot(neighbors, test_accuracies.values(), label=\"Testing Accuracy\")\n    plt.legend()\n    plt.xlabel(\"Number of Neighbors\")\n    plt.ylabel(\"Accuracy\")\n    plt.show()\n    ```\n    :::\n    \n    \n-   Curva de complejidad del modelo\n\n    ![](images/paste-19.png){width=\"80%\"}\n\n### División entrenamiento/prueba + cálculo de precisión\n\n¡Es hora de practicar la división de tus datos en conjuntos de entrenamiento y de prueba con el conjunto de datos `churn_df`!\n\n#### Instrucciones\n\n- Importa `train_test_split` desde `sklear.model_selection`.\n- Divide `X` y `y` en conjuntos de entrenamiento y de prueba, estableciendo `test_size` igual al 20%, `random_state` a `42`, y asegurándote que las proporciones de las etiquetas objetivo reflejan las del conjunto de datos original.\n- Ajusta el modelo `knn` a los datos de entrenamiento.\n- Calcula e imprime la precisión del modelo para los datos de prueba.\n\n::: {#6b41bebe .cell execution_count=13}\n``` {.python .cell-code}\n# Import the module\nfrom sklearn.model_selection import train_test_split\n\nX = churn_df.drop('churn', axis=1).values\ny = churn_df['churn'].values\n\n# Split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\nknn = KNeighborsClassifier(n_neighbors=5)\n\n# Fit the classifier to the training data\nknn.fit(X_train, y_train)\n\n# Print the accuracy\nprint(knn.score(X_test, y_test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.8740629685157422\n```\n:::\n:::\n\n\n::: {.callout-important title=\"¿Por qué usar `stratify=y`?\" collapse=\"true\"}\nEn problemas de **clasificación**, `stratify=y` hace que el **split** mantenga en **train** y **test** la misma proporción de clases que hay en el conjunto original.\nEsto es especialmente útil cuando las clases están **desbalanceadas** (por ejemplo, pocos casos de `churn=1`), porque evita que el conjunto de prueba quede con muy pocos (o cero) ejemplos de la clase minoritaria, lo que haría que métricas como *accuracy* sean engañosas.\n:::\n\n¡Excelente! En unas pocas líneas de código se dividió un conjunto de datos, se ajustó un modelo KNN y se encontró que su precisión es del 87%.\n\n### Sobreajuste e infraajuste\n\nInterpretar la complejidad del modelo es una buena forma de evaluar el rendimiento del aprendizaje supervisado. Tu objetivo es producir un modelo que pueda interpretar la relación entre las características y la variable objetivo, así como generalizar bien cuando se exponga a nuevas observaciones.\n\n::: {.callout-note collapse=\"true\"}\nPara poder hacer el ejecicio fue necesario cargar el dataset `Telecom Churn Data.csv` para posteriormente dividir las características y la variable objetivo, similar al ejercicio en DAtaCamp.\n:::\n\n::: {#f9a950db .cell execution_count=14}\n``` {.python .cell-code}\nruta1 = './data/Telecom Churn Data.csv'\nchurn_df1 = pd.read_csv(ruta1)\n\nX = churn_df1.drop('churn', axis=1).values\ny = churn_df1['churn'].values\n\n# División de entrenamiento y test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n```\n:::\n\n\n#### Instrucciones\n\n- Crea `neighbors` como una matriz `numpy` de valores desde `1` hasta `12` inclusive.\n- Instancia un `KNeighborsClassifier`, con el número de vecinos igual al iterador `neighbor`\n- Ajusta el modelo a los datos de entrenamiento.\n- Calcula las puntuaciones de precisión del conjunto de entrenamiento y del conjunto de prueba por separado utilizando el método `.score()` y asigna los resultados a los diccionarios `train_accuracies` y `test_accuracies` respectivamente, utilizando el iterador `neighbor` como índice.\n\n::: {#14ed0ef4 .cell execution_count=15}\n``` {.python .cell-code}\n# Create neighbors\nneighbors = np.arange(1, 13)\ntrain_accuracies = {}\ntest_accuracies = {}\n\nfor neighbor in neighbors:\n\n    # Set up a KNN Classifier\n    knn = KNeighborsClassifier(n_neighbors=neighbor)\n\n    # Fit the model \n    knn.fit(X_train, y_train)\n\n    # Compute accuracy\n    train_accuracies[neighbor] = knn.score(X_train, y_train)\n    test_accuracies[neighbor] = knn.score(X_test, y_test)\n\nprint(neighbors, '\\n', train_accuracies, '\\n', test_accuracies)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[ 1  2  3  4  5  6  7  8  9 10 11 12] \n {np.int64(1): 1.0, np.int64(2): 0.8909454727363681, np.int64(3): 0.8979489744872436, np.int64(4): 0.8704352176088044, np.int64(5): 0.8729364682341171, np.int64(6): 0.8594297148574287, np.int64(7): 0.863431715857929, np.int64(8): 0.8574287143571786, np.int64(9): 0.8594297148574287, np.int64(10): 0.8574287143571786, np.int64(11): 0.8569284642321161, np.int64(12): 0.8564282141070535} \n {np.int64(1): 0.7893553223388305, np.int64(2): 0.8425787106446777, np.int64(3): 0.8403298350824587, np.int64(4): 0.856071964017991, np.int64(5): 0.8478260869565217, np.int64(6): 0.8538230884557722, np.int64(7): 0.8545727136431784, np.int64(8): 0.856071964017991, np.int64(9): 0.856071964017991, np.int64(10): 0.856071964017991, np.int64(11): 0.8583208395802099, np.int64(12): 0.8545727136431784}\n```\n:::\n:::\n\n\n¿Notas cómo la precisión del entrenamiento disminuye a medida que el número de vecinos inicialmente aumenta, y viseversa para la precisión de la prueba? Estas puntuaciones serían mucho más fáciles de interpretar en un gráfico de líneas, así que vamos a producir una curva de complejidad del modelo con estos resultados.\n\n\n### Visualizar la complejidad del modelo\n\nAhora que has calculado la precisión del modelo KNN en los conjuntos de entrenamiento y prueba utilizando varios valores de `n_neighbors`, puedes crear una curva de complejidad del modelo para visualizar cómo cambia el rendimiento a medida que el modelo se hace menos complejo.\n\n#### Instrucciones\n\n- Añade un título `\"KNN: Varyin Number of Neighbors\"`.\n- Traza el método `.values()` de `train_accuracies` en el eje y contra `neighbors` en el eje x, con una etiqueta `\"Training Accuracy\"`.\n- Traza el método `.values()` de `test_accuracies` en el eje y contra `neighbors` en el eje x, con una etiqueta `\"Testing Accuracy\"`.\n\n::: {#dd96c638 .cell execution_count=16}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\n# Add a title\nplt.title(\"KNN: Varying Number of Neighbors\")\n\n# Plot training accuracies\nplt.plot(neighbors, train_accuracies.values(), label='Training Accuracy')\n\n# Plot test accuracies\nplt.plot(neighbors, test_accuracies.values(), label='Testing Accuracy')\n\nplt.legend()\nplt.xlabel(\"Number of Neighbors\")\nplt.ylabel(\"Accuracy\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](01_Clasificacion_files/figure-html/cell-17-output-1.png){}\n:::\n:::\n\n\nObserva cómo la precisión del entrenamiento disminuye y la precisión de la prueba aumenta a medida que el número de vecinos aumenta. Para el conjunto de prueba, la precisión alcanza su punto máximo con 7 vecinos, lo que sugiere que es el valor óptimo para el modelo. ¡Ahora exploremos los modelos de regresión!\n\n",
    "supporting": [
      "01_Clasificacion_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}